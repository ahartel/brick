\chapter{Recipes}
\label{chap:recipes}
To run and test the examples in this chapter, you can go to to the path that is
specified for each example.

Prior to running any example you need to check that all \ti{Cadence Incisive}
programs are accessible and you need to follow the instructions in
\cref{sec:install}.

\section{Simulating with Cadence Incisive}
For background information about simulating \gls{HDL} design with \ti{Cadence
Incisive} please see \cref{chap:incisive}.
\subsection{Basic RTL simulation}
\label{sec:ius_basic_rtl}
The most basic \tf{wscript} for RTL simulation with \ti{Cadence Incisive} is
shown in the following listing. A running example of it can be found in the
folder \tf{test/cadence\_ius/sim\_rtl\_only\_0}.
\begin{lstwscript}
def configure(cfg):
    cfg.load('cadence_ius')

def build(bld):
    bld.load('brick_general')
    bld ( features = 'cds_write_libs' )
 
    bld (
        name = 'compile_top',
        features = 'cds_compile_hdl',
        source = bld.convert_string_paths(
            [
                'source_file0',
                'source_file1',
            ]),
        verilog_search_paths = bld.convert_string_paths(
            [
                'search_path0',
                'search_path1',
            ]
        ),
    )
 
    bld.add_group()
 
    bld (
        toplevel = 'worklib.tb_top',
        features = 'cds_elab',
        always = True
    )

def run(bld):
    bld (
        features = 'ncsim',
        toplevel = 'worklib.tb_top',
    )

from waflib.Build import BuildContext
class one(BuildContext):
    cmd = 'run'
    fun = 'run'
}
\end{lstwscript}

This \tf{wscript} sets up calls to \tf{ncvlog} for all files given to the
\ti{compile\_top} task generator. Afterwards it runs \tf{ncelab} on the given
toplevel unit. When typing \mint{bash}'./waf run',
\tf{ncsim} is invoked. By default, this starts a GUI version of \tf{ncsim}.
\subsubsection{Disabling the \tf{ncsim} GUI}
You can also start \tf{ncsim} without a GUI, by modifying the \tf{configure}
function of the wscript like this:
\begin{lstwscript}
def configure(cfg):
    cfg.load('cadence_ius')
    cfg.env['NCSIM_OPTIONS'].remove('-gui')
\end{lstwscript}

\subsubsection{Changing the worklib's name}
Any working library that is explicitely given by the user (i.e. written into
the \tf{hdl.var} file has to be listed in the \tf{cds.lib} file as well and the
directory that contains the library has to be created by the user.

To tell the \ti{Incisive} tools to use a different working library the
\tf{wscript} has to be modified like this:
\begin{lstwscript}
def configure(conf):
    cfg.load('cadence_ius')
    cfg.env.CDS_LIBS = ['./myworklib']
    cfg.env.CDS_WORKLIB = 'myworklib'

def build(bld):
    ...
    bld (
        toplevel = 'mywork.tb_top',
        features = 'cds_elab',
        always = True
    )

def run(bld):
    bld (
        features = 'ncsim',
        toplevel = 'worklib.tb_top',
    )

...
\end{lstwscript}
This example code can be found in the folder
\tf{test/cadence\_ius/sim\_rtl\_only\_0} of the repository.

It is worth noting that the workflow presented in this subsection also has to
be used for \gls{RVM}.

\clearpage
\subsection{Behavioral-Based Mixed-signal simulation}
\label{sec:ius_behave_rtl}
If you want to use Verilog-AMS behaioral models that contain analog blocks or
signals of discipline electrical, the following \tf{wscript} snippet can help
you to set up a simulation.

\begin{lstwscript}
import os

def configure(conf):
    conf.env.CDS_MIXED_SIGNAL = True

    conf.load('cadence_ius')

    conf.env['NCELAB_OPTIONS'].extend([
        '-amsconnrules', 'ConnRules_12V_full_fast',
        'ConnRules_12V_full_fast',
    ])

def build(bld):
    bld.load('brick_general')
    bld ( features = 'cds_write_libs' )

    bld (
        name = 'compile_top',
        features = 'cds_compile_hdl',
        source = bld.convert_string_paths(
            [
                'source_file0',
                'source_file1',
                os.environ['BRICK_DIR']+'/source/verilog-ams/ConnRules12.vams',
            ]),
        verilog_search_paths = bld.convert_string_paths(
            [
                'search_path0',
                'search_path1',
            ]
        ),
    )
    bld.add_group()
    bld (
        toplevel = 'worklib.tb',
        features = 'cds_elab',
        always = True
    )   

def run(bld):
    bld (
        features = 'ncsim',
        toplevel = 'worklib.tb',
        stop_time = '100n',
    )   

from waflib.Build import BuildContext
class one(BuildContext):
    cmd = 'run'
    fun = 'run'
\end{lstwscript}

In this listing, compared to the listing in \cref{sec:ius_basic_rtl}, lines 2,
6-9, 22 and 42 have been added and mark the important changes. The rest of the
listing has remained unchanged. The additional lines' purposes are described
next:
\begin{description}
    \item[Line 2:] The environment variable \tf{CDS\_MIXED\_SIGNAL} enables the
 mixed-signal flow. In particular, it changes the default options that are
 passed to \tf{ncelab} and tells to the task generator for the \tf{ncsim} task
 to create and use an analog control file.
    \item[Lines 6-9:] These add options to the \tf{ncelab} call that tell it to
 use the connect rules that are defined in line 22.
    \item[Line 22:] Adds a Verilog-AMS source file to the compilation process.
 This file defines connect rules for the automatic connect module insertion
 process that is handled by \tf{ncelab}.
    \item[Line 42:] Tells the task generator for the \tf{ncsim} task to set the
 stop time of the transient simulation to 100 ns.
\end{description}

\subsection{Schematic-Based Mixed-signal simulation}

\begin{lstwscript}
import os

def configure(conf):
    conf.env.CDS_MIXED_SIGNAL = True

    conf.load('cadence_ius')
    conf.load('cadence_mixed_signal')
                                                                                       
    conf.env['CDS_LIBS']['brick_test'] = '../../cdslib/'
    conf.env.CDS_LIB_INCLUDES = [ 
        '$TSMC_DIR/oa/cds.lib',
    ]   

    conf.env['NCELAB_OPTIONS'].extend([
        '-amsconnrules', 'ConnRules_12V_full_fast', 'ConnRules_12V_full_fast',
        '-libverbose',
        '-modelpath',
        os.environ['TSMC_DIR']+'/oa/models/spectre/toplevel.scs(tt_lib)',
    ])

def build(bld):
    bld.load('brick_general')
    bld ( features = 'cds_write_libs' )

    bld (
        feature = 'cds_mixed_signal',
        cellview = 'lib.cell:view',
    )

    bld (
        name = 'compile_top',
        source = bld.convert_string_paths(
            [
                'source_file0',
                'source_file1',
                os.environ['BRICK_DIR']+'/source/verilog-ams/ConnRules12.vams',
            ]),
        features = 'cds_compile_hdl',
        verilog_search_paths = bld.convert_string_paths(
            [
                'search_path0',
                'search_path1',
            ]
    )
    bld.add_group()
    bld (
        toplevel = 'worklib.tb',
        features = 'cds_elab',
        always = True
    )

def run(bld):
    bld (
        features = 'ncsim',
        toplevel = 'worklib.tb',
        stop_time = '100n',
    )

from waflib.Build import BuildContext
class one(BuildContext):
    cmd = 'run'
    fun = 'run'
\end{lstwscript}

In this listing, compared to the listing in \cref{sec:ius_behave_rtl}, lines
25-28 contain the important changes. Otherwise the snippet has remained
unchanged (except for the implicit changes in the anonymous source file
placeholders).
\begin{description}
    \item[Line 42:] Adds a task generator call that creates 2 tasks, one for
        a netlisting task and a second one for a compilation task that compiles
        the resulting netlist.
\end{description}

\warningsign Note that the \ti{cadence\_mixed\_signal} tool needs a cell view
of type \ti{config}. If you don't already have a \ti{config} cell view at hand,
you can let \ti{brICk} create one by adding the following lines to your
\tf{wscript}.
\begin{lstwscript}
bld (                                                                          
    features = 'cds_config',
    name = 'create_some_config',
    libs = ['lib','tsmcN65'],
    cellview = 'lib.cell:config',
    update_outputs = True
)
\end{lstwscript}

Here, the \tf{cellview} property defines the toplevel cell view of the
hierarchy. The output cell view (the one that will be created by \ti{brICk})
will, by default, have the same cell name as the source cell view but will
reside in the working library and have view name \tf{brick\_config}. To
override this behavior, you can add the property \tf{config\_cellview} to the
call. It has to contain a string of type \tf{lib.cell:view}.

The \tf{update\_outputs} property has to be set to \ti{True}, if the file
that will be generated by this task does not reside in the build directory.

\subsection{Layout-Based Mixed-signal simulation}

%\section{Simulating with Modelsim}
%\subsection{Basic RTL simulation}
%
%\begin{lstwscript}
%def configure(conf):
%    conf.load('brick_general')
%    conf.load('modelsim')
%
%def build(bld):
%    bld.load('brick_general')
%
%    bld (
%        name = 'compile_top',
%        source = bld.convert_string_paths(
%            [   
%                'tb.sv',
%                'top.sv',
%            ])  
%            ,   
%        features = 'modelsim',
%    )   
%
%
%def run(bld):
%    bld (
%        features = 'vsim',
%        toplevel = 'worklib.tb',
%    )   
%
%from waflib.Build import BuildContext
%class one(BuildContext):
%    cmd = 'run'
%    fun = 'run'
%\end{lstwscript}

\section{Checking and Extracting Layouts with Calibre}

